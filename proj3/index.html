<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CS 180 Portfolio: Project 3</title>
    <link rel="stylesheet" href="../style.css" />
  </head>
  <body>
    <header>
      <h1>Alex Luu's CS 180 Project Portfolio</h1>
      <h2>Project 3: [Auto]Stitching Photo Mosaics</h2>
    </header>
    <main class="project-content">
      <p class="back-home"><a href="../index.html">&larr; Back to Home</a></p>

      <div class="section">
        <h2>Part A.1: Shoot the Pictures</h2>

        <h3>Mosaics Images</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img src="images/forest_left.jpeg" alt="Forest left" />
              <p>Forest Left</p>
            </div>
            <div>
              <img src="images/forest_center.jpeg" alt="Forest center" />
              <p>Forest Center</p>
            </div>
            <div>
              <img src="images/forest_right.jpeg" alt="Forest right" />
              <p>Forest Right</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img src="images/lane_left.jpeg" alt="Street right" />
              <p>Street Left</p>
            </div>
            <div>
              <img src="images/lane_center.jpeg" alt="Street center" />
              <p>Street Center</p>
            </div>
            <div>
              <img src="images/lane_right.jpeg" alt="Street right" />
              <p>Street Right</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/hallway_left.jpeg"
                alt="Hallway left"
                style="max-height: 400px"
              />
              <p>Wheeler Hall Left</p>
            </div>
            <div>
              <img
                src="images/hallway_right.jpeg"
                alt="Hallway right"
                style="max-height: 400px"
              />
              <p>Wheeler Hall Right</p>
            </div>
          </div>
        </div>
        <h3>Rectification Images</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/powerbox.jpeg"
                alt="electrical panel"
                style="max-height: 400px"
              />
              <p>Electrical Panel</p>
            </div>
            <div>
              <img
                src="images/evans.jpeg"
                alt="Evans hall"
                style="max-height: 550px"
              />
              <p>Evans Hall</p>
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Part A.2: Recover Homographies</h2>
        <p>
          In this part, I wrote the <code>computeH</code> function that computes
          the homography matrix from the 2 sets of points. I also wrote a point
          selector function that aids in selecting points visually. After
          selecing points, I would print and save the outputs for
          reproducibility. The images below are the points I selected to be
          mapped to a square output. To see the correspondences for the mosaic
          images, please check section A.4.
        </p>
        <p>
          The system of equations I used to solve for the homography matrix is
          shown below. Note that it is only shown for a single data point. (x,
          y) is the point on the image to be transformed, and (x', y') is the
          corresponding point on the output image. The homography matrix H is
          represented by the variables a, b, c, d, e, f, g, and h.
        </p>
        <pre>
                                      [[a]
                                       [b]
                                       [c]
[[x, y, 1,  0,  0,  0, -x*x', -y*x']   [d]   =   [[x']
 [ 0,  0,  0, x, y, 1, -x*y', -y*y']]  [e]        [y']]
                                       [f]
                                       [g]
                                       [h]]
        </pre>

        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-2_powerbox_points.jpg"
                alt="Electrical panel points"
              />
              <p>Electrical Panel Points</p>
            </div>
            <div>
              <pre>
H: 
[[ 2.73863262e-01 -2.11616216e-02 -8.62139265e+01]
 [-5.00062062e-02  2.16144295e-01 -2.99203946e+01]
 [-5.53283959e-04  2.29394000e-05  1.00000000e+00]]
              </pre>
            </div>
          </div>

          <div class="flex-row">
            <div>
              <img
                src="images/part-a-2_evans_points.jpg"
                alt="Evans hall points"
              />
              <p>Evans Hall Points</p>
            </div>
            <div>
              <pre>
H: 
[[ 5.02152033e-01 -3.83072252e-02 -1.43194347e+02]
 [-1.33960566e-02  4.73944947e-01 -1.21724917e+02]
 [-4.66894335e-05 -2.02028103e-04  1.00000000e+00]]
              </pre>
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Part A.3: Warp the Images</h2>
        <p>
          In this section, I implemented two interpolation methods from scratch:
          Nearest Neighbor and Bilinear. These methods are used in conjunction
          with warping to transform images based on a homography matrix.
        </p>
        <p>
          Nearest Neighbor interpolation rounds coordinates to the nearest pixel
          value, offering a faster but more pixelated result. Bilinear
          interpolation uses a weighted average of four neighboring pixels,
          providing a higher quality, smoother output at the cost of increased
          computational time. The rectification results below demonstrate the
          visual differences between these two approaches.
        </p>
        <p>
          I initially implemented both using for loops that looped through each
          output pixel. Both were slow, but Nearest Neighbor was significantly
          faster than Bilinear. I then optimized both methods using NumPy's
          vectorization to remove all loops. This resulted in an almost instant
          output for both methods.
        </p>
        <p>
          To implement these methods, I wrote a helper function that would
          determine the full output canvas size by warping the four corners of
          the input image. I would then scale the 0-centered output coordinates
          with the bounds from the 4 corners to be able to map the entire image.
          From these scaled points, I passed them through the inverse homography
          matrix to get the corresponding input image coordinates. Finally, I
          would apply the interpolation methods to create the output image.
        </p>

        <h3>Rectification Results</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-3_powerbox_rectification_nn.png"
                alt="Powerbox Rectification Nearest Neighbor"
              />
              <p>Electrical Panel Rectification (Nearest Neighbor)</p>
            </div>
            <div>
              <img
                src="images/part-a-3_powerbox_rectification_bl.png"
                alt="Powerbox Rectification Bilinear"
              />
              <p>Electrical Panel Rectification (Bilinear)</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-3_evans_rectification_nn.png"
                alt="Evans Hall Rectification Nearest Neighbor"
              />
              <p>Evans Hall Rectification (Nearest Neighbor)</p>
            </div>
            <div>
              <img
                src="images/part-a-3_evans_rectification_bl.png"
                alt="Evans Hall Rectification Bilinear"
              />
              <p>Evans Hall Rectification (Bilinear)</p>
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Part A.4: Blend the Images into a Mosaic</h2>
        <p>
          To create the image mosaics, I used the Bilinear warp method on one
          image at a time. If I had 3 images, I would choose a center image that
          would remain in its original perspective. The other images would then
          be warped to align with the center image. For cases with only 2
          images, I would warp both to a chosen perspective. I computed the
          required homography matrix for each warp and applied the
          transformation. Next, I determined the final mosaic canvas size by
          calculating scaling factors from the corners of the original image
          after passing them through the homography transformation.
        </p>
        <p>
          My initial approach placed the center (unwarped) image on the canvas
          first, then overlaid the warped image on top. This created a
          noticeable hard seam between the images. To address this, I
          implemented Laplacian stack blending (using helper code from Project
          2) to create a smooth transition. Since the warped image was
          positioned on top, I created a mask covering the entire warped image.
          My first attempt passed the original images through the Laplacian
          stack function, but this introduced a black seam due to missing
          pixels. To resolve this, I created an inverse mosaic by placing the
          warped image first, then overlaying the center image. This became the
          input for the mask's 0 pixels, while the original hard-edge overlay
          was used for the 1 pixels. Although improved, a slight hard edge
          remained due to the input image boundary. To eliminate this, I reduced
          the mask size using blurring followed by absolute filtering, which
          allowed the blending to avoid the hard edge entirely.
        </p>

        <h3>Forest Mosaic Results</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4-forest_CL.jpg"
                alt="Forest Center Left"
              />
              <p>Forest Center and Left Base Points</p>
            </div>
            <div>
              <img
                src="images/part-a-4-forest_LC.jpg"
                alt="Forest Left Center"
              />
              <p>Forest Center and Left Warp Points</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4-forest_CR.jpg"
                alt="Forest Center Right"
              />
              <p>Forest Intermediate and Right Base Points</p>
            </div>
            <div>
              <img
                src="images/part-a-4-forest_RC.jpg"
                alt="Forest Right Center"
              />
              <p>Forest Intermediate and Right Warp Points</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4_forest_mosaic.png"
                alt="Forest Mosaic"
              />
              <p>Forest Mosaic</p>
            </div>
          </div>
        </div>

        <h3>Street Mosaic Results</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img src="images/part-a-4-lane_CL.jpg" alt="Street Center Left" />
              <p>Street Center and Left Base Points</p>
            </div>
            <div>
              <img src="images/part-a-4-lane_LC.jpg" alt="Street Left Center" />
              <p>Street Center and Left Warp Points</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4-lane_CR.jpg"
                alt="Street Center Right"
              />
              <p>Street Intermediate and Right Base Points</p>
            </div>
            <div>
              <img
                src="images/part-a-4-lane_RC.jpg"
                alt="Street Right Center"
              />
              <p>Street Intermediate and Right Warp Points</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img src="images/part-a-4_lane_mosaic.png" alt="Street Mosaic" />
              <p>Street Mosaic</p>
            </div>
          </div>
        </div>

        <h3>Wheeler Hallway Mosaic Results</h3>
        <div class="flex-column">
          <div class="flex-row"></div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4-hallway_LC.jpg"
                alt="Hallway Left Center"
              />
              <p>Hallway Left Warp Points To Imaginary Image</p>
            </div>
            <div>
              <img
                src="images/part-a-4-hallway_CR.jpg"
                alt="Hallway Center Right"
              />
              <p>Hallway Intermediate and Right Base Points</p>
            </div>
            <div>
              <img
                src="images/part-a-4-hallway_RC.jpg"
                alt="Hallway Right Center"
              />
              <p>Hallway Intermediate and Right Warp Points</p>
            </div>
          </div>
          <div>
            <img
              src="images/part-a-4_hallway_mosaic.png"
              alt="Hallway Mosaic"
              style="max-height: 650px"
            />
            <p>Wheeler Hallway Mosaic</p>
          </div>
        </div>
      </div>

      <div style="margin: 80px"></div>
      <hr />
      <div style="margin: 30px"></div>

      <div class="section">
        <h2>Part B.1: Harris Corner Detection</h2>
        <p>
          In this part, I implemented the Harris Interest Point Detector with
          ANMS to identify corner points in images. For the Harris corner
          detector, I used the starter code and modified it with a higher raw
          threshold and larger local maximum window size to reduce the number of
          points.
        </p>
        <p>
          To implement Adaptive Non-Maximal Suppression (ANMS), I computed a
          suppression radius for each corner point. This formula is provided in
          the paper "Multi-Image Matching using Multi-Scale Oriented Patches".
          The suppression radius is defined as the minimum distance to another
          corner that is stronger scaled by a factor of 0.9. By selecting
          corners with the largest suppression radii, we get a well-distributed
          set of feature points across the image. From this, I took the top 500
          corners.
        </p>

        <h3>Harris Corners on Street</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-1_lane_left_harris.jpg"
                alt="Lane Left Harris Corners"
              />
              <p>Street Left Corners (Before ANMS)</p>
            </div>
            <div>
              <img
                src="images/part-b-1_lane_left_anms_harris.jpg"
                alt="Lane Left ANMS Harris Corners"
              />
              <p>Street Left Corners (After ANMS)</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-1_lane_center_harris.jpg"
                alt="Lane Center Harris Corners"
              />
              <p>Street Center Corners (Before ANMS)</p>
            </div>
            <div>
              <img
                src="images/part-b-1_lane_center_anms_harris.jpg"
                alt="Lane Center ANMS Harris Corners"
              />
              <p>Street Center Corners (After ANMS)</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-1_lane_right_harris.jpg"
                alt="Lane Right Harris Corners"
              />
              <p>Street Right Corners (Before ANMS)</p>
            </div>
            <div>
              <img
                src="images/part-b-1_lane_right_anms_harris.jpg"
                alt="Lane Right ANMS Harris Corners"
              />
              <p>Street Right Corners (After ANMS)</p>
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Part B.2: Feature Descriptor Extraction</h2>
        <p>
          In this section, I implemented feature descriptor extraction for each
          detected corner point. I extracted a 40x40 pixel window around each
          corner. I then downsampled this to an 8x8 patch and normalized it so
          that it had zero mean and unit variance to make it more robust.
        </p>

        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-2_lane_patches.jpg"
                alt="Feature Descriptor Patches"
              />
              <p>
                Some of the 8x8 Feature Descriptors from Street Center Image
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Part B.3: Feature Matching</h2>
        <p>
          In this section, I implemented feature matching between pairs of
          images. For each feature descriptor in the first image, I computed the
          sum of squared differences (SSD) with all descriptors in the second
          image to find potential matches.
        </p>
        <p>
          To ensure robust matching, I used Lowe's ratio test: for each feature,
          I compared the distance to the nearest neighbor with the distance to
          the second-nearest neighbor. A match is only accepted if the ratio of
          these distances is below a 0.3. This helps filter out ambiguous
          matches where multiple features look similar.
        </p>

        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-3_lane_matches.jpg"
                alt="Feature Matches Between Lane Images"
              />
              <p>
                Some of the Feature Matches Between Street Center and Left
                Images
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-3_lane_matches_image.jpg"
                alt="Feature Matches Visualization"
              />
              <p>
                Some of the Feature Matches on Original Images (Street Left and
                Center)
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h2>Part B.4: RANSAC for Robust Homography</h2>
        <p>
          In this final section, I implemented 4-point RANSAC to compute a
          homography estimate from the noisy feature matches. RANSAC (RANdom
          SAmple Consensus) is an iterative algorithm that identifies inliers in
          the presence of outliers.
        </p>
        <p>
          The algorithm I implemented works as follows: Randomly select 4
          feature matches and compute a homography from these points. Then, test
          all other matches against this homography to count inliers within a
          threshold of 40 pixels. To measure difference, I used L2 distance
          between the actual point and the projected point. I repeated this
          process for 10000 iterations (by default). Finally, I recomputed the
          homography using all inliers to get a robust estimate.
        </p>
        <p>
          Using the robust homography from RANSAC, I then adapted the code from
          Part A to create automatic image mosaics. Below, I show comparisons
          between manually stitched results (from Part A) and automatically
          stitched results (using the automatic feature detection and matching
          pipeline from Part B).
        </p>

        <h3>Forest Mosaic</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4_forest_mosaic.png"
                alt="Forest Mosaic Manual"
              />
              <p>Forest Mosaic (Manual)</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-4_forest_mosaic.png"
                alt="Forest Mosaic Automatic"
              />
              <p>Forest Mosaic (Automatic)</p>
            </div>
          </div>
        </div>

        <h3>Street Mosaic</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4_lane_mosaic.png"
                alt="Street Mosaic Manual"
              />
              <p>Street Mosaic (Manual)</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-4_lane_mosaic.png"
                alt="Street Mosaic Automatic"
              />
              <p>Street Mosaic (Automatic)</p>
            </div>
          </div>
        </div>

        <h3>Wheeler Hallway Mosaic</h3>
        <div class="flex-column">
          <div class="flex-row">
            <div>
              <img
                src="images/part-a-4_hallway_mosaic.png"
                alt="Hallway Mosaic Manual"
                style="max-height: 650px"
              />
              <p>Wheeler Hallway Mosaic (Manual)</p>
            </div>
          </div>
          <div class="flex-row">
            <div>
              <img
                src="images/part-b-4_hallway_mosaic.png"
                alt="Hallway Mosaic Automatic"
                style="max-height: 650px"
              />
              <p>Wheeler Hallway Mosaic (Automatic)</p>
            </div>
          </div>
        </div>

        <h3>Manual vs Automatic Point Selection</h3>
        <p>
          As seen above, it seem like the manual method produces better results
          on average. For the forest and street mosaics, both the manual and
          automatic performed well. However, for the hallway mosaic, the
          automatic method struggled with the bar light on the ceiling. This is
          probably because the ceiling area is mostly symmetrical which means
          there were too many similar points. For example, the bar of light
          closest to the camera is not fully shown on either original pictures.
          However, the part of the light that holds it to the ceiling and the 2
          long edges are very similar in both images (since it is symmetrical).
          This results in a significant incorrect match since which hurts how
          the homography matrix is calculated (since least squares is not robust
          to outliers). In contrast, the manual method allows for more control
          over which points are selected, which can help avoid these types of
          issues.
        </p>
      </div>
    </main>
    <footer>
      <p>&copy; 2025 Alex Luu</p>
    </footer>
  </body>
</html>
